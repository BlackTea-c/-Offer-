# 排序算法笔记



<details>
  <summary>冒泡排序</summary>
<font color="red">冒泡排序只会操作相邻的两个数据。</font>


冒泡操作是指，比较相邻的两个元素，看是否满足大小关系的要求，如果不满足就将它们互换。

因为越小(或越大)的元素会经由交换慢慢“浮”到数列的顶端，所以一次冒泡会让至少一个元素移动到它应该在的位置，重复 n 次，就完成了 n 个数据的排序工作。

冒泡过程还可以优化一下，当某次冒泡操作已经没有数据交换时，说明已经达到完全有序，不用再继续执行后续的冒泡操作。

冒泡排序的代码参见：<font color="blue">冒泡排序.py</font>



1.是否原地排序算法？

冒泡的过程只涉及相邻数据的交换操作，只需要常量级的临时空间，所以它的空间复杂度为 O(1)，是一个原地排序算法。

2.是否稳定排序？

因为比较的时候我们用的是a[j]>a[j+1]才会交换，即两个元素相等时不会进行交换，所以冒泡排序是一个稳定的排序。

3.时间复杂度分析

最好情况下，要排序的数据已经是有序的了，我们只需要进行一次冒泡操作，就可以结束了，所以最好情况时间复杂度是 O(n)。

最坏的情况是，要排序的数据刚好是倒序排列的，我们需要进行 n 次冒泡操作：

所以最坏情况时间复杂度为O(n^2) 。

那么平均情况下的时间复杂度呢？

对于包含 n 个数据的数组，这 n 个数据就有 n! 种排列方式。不同的排列方式，冒泡排序执行的时间是不同的。如果用概率论方法定量分析平均时间复杂度，涉及的数学推理和计算就会很复杂。有一种思路是通过"有序度"和"逆序度"来分析平均时间复杂度。

有序度是数组中具有有序关系的元素对的个数。完全有序的数组的有序度叫做满有序度。

有序元素对：a[i]<=a[j]，如果i<j  则有序度+1

逆序元素对：a[i]>a[j]，如果i<j

逆序度=满有序度-有序度，满有序度=n(n-1)/2  (这里稍微自己算一下,如果是满的，则1+2+...n)

排序的过程就是一种增加有序度，减少逆序度的过程，最后达到满有序度，说明排序完成。

冒泡排序包含两个操作原子，比较和交换。每交换一次，有序度就加 1。不管算法怎么改进，交换次数总是确定的，即为逆序度，也就是n*(n-1)/2–初始有序度。

最好情况，交换次数为0，最坏情况，交换次数为n(n-1)/2，我们可以取个中间值 n*(n-1)/4，来表示初始有序度既不是很高也不是很低的平均情况。

也就是说，平均情况下，需要n(n-1)/4次交换操作，比较操作肯定比交换操作多，而复杂度的上限是O(n^2) ，所以平均情况下的时间复杂度就是O(n^2)。

这个推导过程并不严格，但很多时候很实用。
</details>

<details>
  <summary>快速排序</summary>

  快速排序使用分治策略(Divide and Conquer)来把一个序列分为两个子序列。步骤为：

从序列中挑出一个元素，作为"基准"(pivot).
把所有比基准值小的元素放在基准前面，所有比基准值大的元素放在基准的后面（相同的数可以到任一边），这个称为分区(partition)操作。
对每个分区递归地进行步骤1~2，递归的结束条件是序列的大小是0或1，这时整体已经被排好序了。

<font color="red">1.快速排序是稳定的排序算法吗？</font>

快速排序是不稳定的排序算法，不稳定发生在基准元素与A[tail+1]交换的时刻。

比如序列：{1, 3, 4, 2, 8, 9, 8, 7, 5}，基准元素是5，一次划分操作后5要和第一个8进行交换，从而改变了两个元素8的相对次序。

<font color="red">2.快排和归并用的都是分治思想，递推公式和递归代码也非常相似，那它们的区别在哪里呢？</font>

归并排序的处理过程是由下到上的，先处理子问题，然后再合并。而快排正好相反，它的处理过程是由上到下的，先分区，然后再处理子问题。归并排序虽然是稳定的、时间复杂度为 O(nlogn) 的排序算法，但是它是非原地排序算法，主要原因是合并函数无法在原地执行。快速排序通过设计巧妙的原地分区函数，可以实现原地排序，解决了归并排序占用太多内存的问题。

 3.性能分析

 最差时间复杂度——每次选取的基准都是最大（或最小）的元素，导致每次只划分出了一个分区，需要进行n-1次划分才能结束递归，时间复杂度为O(n^2)

 最优时间复杂度——每次选取的基准都是中位数，这样每次都均匀的划分出两个分区，只需要logn次划分就能结束递归，时间复杂度为O(nlogn)

 平均时间复杂度——O(nlogn)

 空间复杂度——主要是递归造成的栈空间的使用(用来保存left和right等局部变量)，取决于递归树的深度，一般为O(logn)，最差为O(n)
</details>

<details>
  <summary>归并排序</summary>

  归并排序是创建在归并操作上的一种有效的排序算法，效率为O(nlogn)，1945年由冯·诺伊曼首次提出。

归并排序的实现分为递归实现与非递归(迭代)实现。递归实现的归并排序是算法设计中分治策略的典型应用，我们将一个大问题分割成小问题分别解决，然后用所有小问题的答案来解决整个大问题。非递归(迭代)实现的归并排序首先进行是两两归并，然后四四归并，然后是八八归并，一直下去直到归并了整个数组。

归并排序使用的就是分治思想。分治是一种解决问题的处理思想，递归是一种编程技巧，这两者并不冲突。

如何用递归代码实现归并排序？

要想写出归并排序的代码，我们先写出归并排序的递推公式，有了递推公式，转化成代码就简单多了。

递推公式：

merge_sort(p…r) = merge(merge_sort(p…q), merge_sort(q+1…r))

终止条件：

p >= r 不用再继续分解

归并排序算法主要依赖归并(Merge)操作。归并操作指的是将两个已经排序的序列合并成一个序列的操作，归并操作步骤如下：

1.申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列
2.设定两个指针，最初位置分别为两个已经排序序列的起始位置
3.比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置
4.重复步骤3直到某一指针到达序列尾
5.将另一序列剩下的所有元素直接复制到合并序列尾

1.是稳定的排序算法吗？

归并排序稳不稳定关键要看 merge() 函数，也就是两个有序子数组合并成一个有序数组的那部分代码。

在合并的过程中，如果 A[p…q] 和 A[q+1…r] 之间有值相同的元素，那我们可以像代码中那样，先把 A[p…q] 中的元素放入 tmp 数组。这样就保证了值相同的元素，在合并前后的先后顺序不变。所以，归并排序是一个稳定的排序算法。

归并排序除了可以对数组进行排序，还可以高效的求出数组小和（即单调和）以及数组中的逆序对，详见这篇博文。

2.时间复杂度分析

递归的适用场景是，一个问题 a 可以分解为多个子问题 b、c，那求解问题 a 就可以分解为求解问题 b、c。问题 b、c 解决之后，我们再把 b、c 的结果合并成 a 的结果。

如果我们定义求解问题 a 的时间是 T(a)，求解问题 b、c 的时间分别是 T(b) 和 T( c)，那我们就可以得到这样的递推关系式：T(a) = T(b) + T(c) + K

其中 K 等于将两个子问题 b、c 的结果合并成问题 a 的结果所消耗的时间。

不仅递归求解的问题可以写成递推公式，递归代码的时间复杂度也可以写成递推公式。

我们假设对 n 个元素进行归并排序需要的时间是 T(n)，那分解成两个子数组排序的时间都是 T(n/2)。我们知道，merge() 函数合并两个有序子数组的时间复杂度是 O(n)。所以，套用前面的公式，归并排序的时间复杂度的计算公式就是：

T(1) = C；n=1时，只需要常量级的执行时间，所以表示为C。

T(n) = 2*T(n/2) + n；n>1
求解T(n)的过程：

T(n) = 2*T(n/2) + n

= 2(2T(n/4) + n/2) + n = 4T(n/4) + 2n

= 4(2T(n/8) + n/4) + 2n = 8T(n/8) + 3*n

= 8(2T(n/16) + n/8) + 3n = 16T(n/16) + 4*n

......

= 2^k * T(n/2^k) + k * n

......
通过这样一步一步分解推导，我们可以得到 T(n) = 2^k *T(n/2^k)+k*n。当 T(n/2^k)=T(1) 时，也就是 n/2^k=1，我们得到 k=log_2n 。我们将 k 值代入上面的公式，得到 T(n)=Cn+nlog_2n 。如果我们用大 O 标记法来表示的话，T(n) 就等于 O(nlogn)。所以归并排序的时间复杂度是 O(nlogn)。

从我们的原理分析和伪代码可以看出，归并排序的执行效率与要排序的原始数组的有序程度无关，所以其时间复杂度是非常稳定的，不管是最好情况、最坏情况，还是平均情况，时间复杂度都是 O(nlogn)。

归并排序的时间复杂度任何情况下都是 O(nlogn)，看起来非常优秀。即便是快速排序，最坏情况下，时间复杂度也是O(n^2) 。但是，归并排序并没有像快排那样，应用广泛，这是为什么呢？因为它有一个致命的“弱点”，那就是归并排序不是原地排序算法。

这是因为归并排序的合并函数，在合并两个有序数组为一个有序数组时，需要借助额外的存储空间。

尽管每次合并操作都需要申请额外的内存空间，但在合并完成之后，临时开辟的内存空间就被释放掉了。在任意时刻，CPU 只会有一个函数在执行，也就只会有一个临时的内存空间在使用。临时内存空间最大也不会超过 n 个数据的大小，所以空间复杂度是 O(n)。

</details>

<details>
  <summary>插入排序</summary>

  插入排序适用处理数据量比较少或者部分有序的数据。

插入算法的核心思想是取未排序区间中的元素，在已排序区间中找到合适的插入位置将其插入，并保证已排序区间数据一直有序。重复这个过程，直到未排序区间中元素为空，算法结束。

插入排序也包含两种操作，一种是元素的比较，一种是元素的移动。

对于不同的查找插入点方法（从头到尾、从尾到头），元素的比较次数是有区别的。但对于一个给定的初始序列，移动操作的次数总是固定的，就等于逆序度。

插入排序在实现上，通常采用in-place排序（即只需用到O(1)的额外空间的排序），因而在从后向前扫描过程中，需要反复把已排序元素逐步向后挪位，为最新元素提供插入空间。

1.是否原地排序算法？

插入排序算法的运行并不需要额外的存储空间，空间复杂度是 O(1)，是一个原地排序算法。

2.是否稳定排序？

在插入排序中，对于值相同的元素，我们可以选择将后面出现的元素，插入到前面出现元素的后面，这样就可以保持原有的前后顺序不变，所以插入排序是稳定的排序算法。

3.时间复杂度分析

如果要排序的数据已经是有序的，我们并不需要搬移任何数据。如果我们从尾到头在有序数据组里面查找插入位置，每次只需要比较一个数据就能确定插入的位置。所以这种情况下，最好是时间复杂度为 O(n)。

如果数组是倒序的，每次插入都相当于在数组的第一个位置插入新的数据，所以需要移动大量的数据，所以最坏情况时间复杂度为 。

对于插入排序来说，每次插入操作都相当于在数组中插入一个数据，循环执行 n 次插入操作，而插入一个数据的平均时间复杂度是 O(n)，所以平均时间复杂度为 。

插入排序不适合对于数据量比较大的排序应用。但是，如果需要排序的数据量很小，比如量级小于千，那么插入排序还是一个不错的选择。插入排序在工业级库中也有着广泛的应用，在STL的sort算法和stdlib的qsort算法中，都将插入排序作为快速排序的补充，用于少量元素的排序（通常为8个或以下）。

冒泡排序和插入排序的时间复杂度都是 O(n2)，都是原地排序算法，为什么插入排序要比冒泡排序更受欢迎呢？

冒泡排序不管怎么优化，元素交换的次数是一个固定值，是原始数据的逆序度。插入排序是同样的，不管怎么优化，元素移动的次数也等于原始数据的逆序度。

但是，从代码实现上来看，冒泡排序的数据交换要比插入排序的数据移动要复杂。

冒泡排序中数据的交换操作：

if a[j] > a[j+1]:
    a[j], a[j+1] = a[j+1], a[j]
    flag = True
如果是C、Java中的实现，则需要3个赋值语句才能完成上述的交换操作。

插入排序中数据的移动操作：

if a[j] > value:
    a[j+1] = a[j]
else:
    break
我们把执行一个赋值语句的时间粗略地计为单位时间（unit_time），然后分别用冒泡排序和插入排序对同一个逆序度是 K 的数组进行排序。用冒泡排序，需要 K 次交换操作，每次需要 3 个赋值语句，所以交换操作总耗时就是 3*K 单位时间。而插入排序中数据移动操作只需要 K 个单位时间。

所以，虽然冒泡排序和插入排序在时间复杂度上是一样的，都是 ，但是如果我们希望把性能优化做到极致，那肯定首选插入排序。

冒泡排序、选择排序，可能就纯粹停留在理论的层面了，学习的目的也只是为了开拓思维，实际开发中应用并不多，但是插入排序还是挺有用的。

这三种排序算法对于小规模数据的排序，用起来非常高效。但是在大规模数据排序的时候，这个时间复杂度还是稍微有点高，更倾向于用时间复杂度为 O(nlogn) 的排序算法。

</details>